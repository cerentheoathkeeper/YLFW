This study investigates the performance and fairness of seven face recognition models CosFace, SphereFace, GhostFaceNet, GhostFaceNetV2, ArcFace, AdaFace, and MagFace on a dataset composed of childrenâ€™s facial images. All models were trained using the same hyperparameters defined in the original paper that introduced the dataset, in order to ensure a consistent and fair comparison.
Evaluation was conducted using standard verification metrics, including FNMR@1e-1, FNMR@1e-2, EER, AUC, and Accuracy. Beyond overall performance, we analyzed the models across four racial subgroups to assess demographic generalization. The results show that GhostFaceNetV2 achieved the best overall accuracy and AUC, followed closely by MagFace, and GhostFaceNet, while AdaFace consistently underperformed across all groups. The racial subgroup analysis further revealed significant disparities in model performance, with higher accuracy typically observed for the African group and lower accuracy for the Caucasian group. These findings highlight the importance of fairnessaware evaluation in the development of face recognition models, particularly in sensitive domains such as child identification.
